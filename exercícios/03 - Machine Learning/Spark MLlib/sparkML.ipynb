{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e4b355d",
   "metadata": {},
   "source": [
    "# Criando sessão Spark e Dataframe com o dataset titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5175d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/07/21 20:02:41 WARN Utils: Your hostname, spark-bigdata, resolves to a loopback address: 127.0.1.1; using 192.168.0.9 instead (on interface enp0s3)\n",
      "25/07/21 20:02:41 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/07/21 20:02:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----+----+\n",
      "|survived|status|  age| sex|\n",
      "+--------+------+-----+----+\n",
      "|     yes| first|adult|male|\n",
      "|     yes| first|adult|male|\n",
      "|     yes| first|adult|male|\n",
      "|     yes| first|adult|male|\n",
      "|     yes| first|adult|male|\n",
      "|     yes| first|adult|male|\n",
      "|     yes| first|adult|male|\n",
      "|     yes| first|adult|male|\n",
      "|     yes| first|adult|male|\n",
      "|     yes| first|adult|male|\n",
      "|     yes| first|adult|male|\n",
      "|     yes| first|adult|male|\n",
      "|     yes| first|adult|male|\n",
      "|     yes| first|adult|male|\n",
      "|     yes| first|adult|male|\n",
      "|     yes| first|adult|male|\n",
      "|     yes| first|adult|male|\n",
      "|     yes| first|adult|male|\n",
      "|     yes| first|adult|male|\n",
      "|     yes| first|adult|male|\n",
      "+--------+------+-----+----+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.master(\"local[*]\")\n",
    "    .appName(\"sparkML\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "df = spark.read.csv(\n",
    "    \"titanic.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True,\n",
    ")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b446ba05",
   "metadata": {},
   "source": [
    "# Trasformando campos string em indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1dafb91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----+----+--------------+------------+---------+---------+\n",
      "|survived|status|  age| sex|survived_index|status_index|age_index|sex_index|\n",
      "+--------+------+-----+----+--------------+------------+---------+---------+\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|\n",
      "+--------+------+-----+----+--------------+------------+---------+---------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "string_indexer_columns = [col for col in df.columns]\n",
    "string_indexer = StringIndexer(inputCols=string_indexer_columns, outputCols=[f\"{col}_index\" for col in string_indexer_columns])\n",
    "model_string_indexer = string_indexer.fit(df)\n",
    "df = model_string_indexer.transform(df)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe2dd1c",
   "metadata": {},
   "source": [
    "# Tratando campos categóricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b156f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----+----+--------------+------------+---------+---------+----------------+-------------+-------------+\n",
      "|survived|status|  age| sex|survived_index|status_index|age_index|sex_index|status_index_ohe|age_index_ohe|sex_index_ohe|\n",
      "+--------+------+-----+----+--------------+------------+---------+---------+----------------+-------------+-------------+\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|   (3,[2],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|   (3,[2],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|   (3,[2],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|   (3,[2],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|   (3,[2],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|   (3,[2],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|   (3,[2],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|   (3,[2],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|   (3,[2],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|   (3,[2],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|   (3,[2],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|   (3,[2],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|   (3,[2],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|   (3,[2],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|   (3,[2],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|   (3,[2],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|   (3,[2],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|   (3,[2],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|   (3,[2],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|   (3,[2],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|\n",
      "+--------+------+-----+----+--------------+------------+---------+---------+----------------+-------------+-------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "from pyparsing import col\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "one_hot_encoder_columns = [col for col in df.columns if col != \"survived_index\" and col.endswith(\"_index\")]\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(inputCols=one_hot_encoder_columns, outputCols=[f\"{col}_ohe\" for col in one_hot_encoder_columns])\n",
    "model_one_hot_encoder = one_hot_encoder.fit(df)\n",
    "df = model_one_hot_encoder.transform(df)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da405624",
   "metadata": {},
   "source": [
    "# Criando vetor das features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cfd6337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----+----+--------------+------------+---------+---------+----------------+-------------+-------------+--------------------+\n",
      "|survived|status|  age| sex|survived_index|status_index|age_index|sex_index|status_index_ohe|age_index_ohe|sex_index_ohe|            features|\n",
      "+--------+------+-----+----+--------------+------------+---------+---------+----------------+-------------+-------------+--------------------+\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|   (3,[2],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[0.0,0.0,1.0,1.0,...|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|   (3,[2],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[0.0,0.0,1.0,1.0,...|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|   (3,[2],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[0.0,0.0,1.0,1.0,...|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|   (3,[2],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[0.0,0.0,1.0,1.0,...|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|   (3,[2],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[0.0,0.0,1.0,1.0,...|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|   (3,[2],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[0.0,0.0,1.0,1.0,...|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|   (3,[2],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[0.0,0.0,1.0,1.0,...|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|   (3,[2],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[0.0,0.0,1.0,1.0,...|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|   (3,[2],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[0.0,0.0,1.0,1.0,...|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|   (3,[2],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[0.0,0.0,1.0,1.0,...|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|   (3,[2],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[0.0,0.0,1.0,1.0,...|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|   (3,[2],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[0.0,0.0,1.0,1.0,...|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|   (3,[2],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[0.0,0.0,1.0,1.0,...|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|   (3,[2],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[0.0,0.0,1.0,1.0,...|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|   (3,[2],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[0.0,0.0,1.0,1.0,...|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|   (3,[2],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[0.0,0.0,1.0,1.0,...|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|   (3,[2],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[0.0,0.0,1.0,1.0,...|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|   (3,[2],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[0.0,0.0,1.0,1.0,...|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|   (3,[2],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[0.0,0.0,1.0,1.0,...|\n",
      "|     yes| first|adult|male|           1.0|         2.0|      0.0|      0.0|   (3,[2],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[0.0,0.0,1.0,1.0,...|\n",
      "+--------+------+-----+----+--------------+------------+---------+---------+----------------+-------------+-------------+--------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "vector_assembler = VectorAssembler(\n",
    "    inputCols=[col for col in df.columns if col.endswith(\"_ohe\")],\n",
    "    outputCol=\"features\")\n",
    "\n",
    "df = vector_assembler.transform(df)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f6d8ee",
   "metadata": {},
   "source": [
    "# Treinamento modelo Random Florest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7b937e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----+------+--------------+------------+---------+---------+----------------+-------------+-------------+--------------------+--------------------+--------------------+----------+\n",
      "|survived|status|  age|   sex|survived_index|status_index|age_index|sex_index|status_index_ohe|age_index_ohe|sex_index_ohe|            features|       rawPrediction|         probability|prediction|\n",
      "+--------+------+-----+------+--------------+------------+---------+---------+----------------+-------------+-------------+--------------------+--------------------+--------------------+----------+\n",
      "|      no|  crew|adult|female|           0.0|         0.0|      0.0|      1.0|   (3,[0],[1.0])|(1,[0],[1.0])|    (1,[],[])| (5,[0,3],[1.0,1.0])|[2.81541705786445...|[0.14077085289322...|       1.0|\n",
      "|      no|  crew|adult|  male|           0.0|         0.0|      0.0|      0.0|   (3,[0],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[1.0,0.0,0.0,1.0,...|[15.7765242749810...|[0.78882621374905...|       0.0|\n",
      "|      no|  crew|adult|  male|           0.0|         0.0|      0.0|      0.0|   (3,[0],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[1.0,0.0,0.0,1.0,...|[15.7765242749810...|[0.78882621374905...|       0.0|\n",
      "|      no|  crew|adult|  male|           0.0|         0.0|      0.0|      0.0|   (3,[0],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[1.0,0.0,0.0,1.0,...|[15.7765242749810...|[0.78882621374905...|       0.0|\n",
      "|      no|  crew|adult|  male|           0.0|         0.0|      0.0|      0.0|   (3,[0],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[1.0,0.0,0.0,1.0,...|[15.7765242749810...|[0.78882621374905...|       0.0|\n",
      "|      no|  crew|adult|  male|           0.0|         0.0|      0.0|      0.0|   (3,[0],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[1.0,0.0,0.0,1.0,...|[15.7765242749810...|[0.78882621374905...|       0.0|\n",
      "|      no|  crew|adult|  male|           0.0|         0.0|      0.0|      0.0|   (3,[0],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[1.0,0.0,0.0,1.0,...|[15.7765242749810...|[0.78882621374905...|       0.0|\n",
      "|      no|  crew|adult|  male|           0.0|         0.0|      0.0|      0.0|   (3,[0],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[1.0,0.0,0.0,1.0,...|[15.7765242749810...|[0.78882621374905...|       0.0|\n",
      "|      no|  crew|adult|  male|           0.0|         0.0|      0.0|      0.0|   (3,[0],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[1.0,0.0,0.0,1.0,...|[15.7765242749810...|[0.78882621374905...|       0.0|\n",
      "|      no|  crew|adult|  male|           0.0|         0.0|      0.0|      0.0|   (3,[0],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[1.0,0.0,0.0,1.0,...|[15.7765242749810...|[0.78882621374905...|       0.0|\n",
      "|      no|  crew|adult|  male|           0.0|         0.0|      0.0|      0.0|   (3,[0],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[1.0,0.0,0.0,1.0,...|[15.7765242749810...|[0.78882621374905...|       0.0|\n",
      "|      no|  crew|adult|  male|           0.0|         0.0|      0.0|      0.0|   (3,[0],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[1.0,0.0,0.0,1.0,...|[15.7765242749810...|[0.78882621374905...|       0.0|\n",
      "|      no|  crew|adult|  male|           0.0|         0.0|      0.0|      0.0|   (3,[0],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[1.0,0.0,0.0,1.0,...|[15.7765242749810...|[0.78882621374905...|       0.0|\n",
      "|      no|  crew|adult|  male|           0.0|         0.0|      0.0|      0.0|   (3,[0],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[1.0,0.0,0.0,1.0,...|[15.7765242749810...|[0.78882621374905...|       0.0|\n",
      "|      no|  crew|adult|  male|           0.0|         0.0|      0.0|      0.0|   (3,[0],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[1.0,0.0,0.0,1.0,...|[15.7765242749810...|[0.78882621374905...|       0.0|\n",
      "|      no|  crew|adult|  male|           0.0|         0.0|      0.0|      0.0|   (3,[0],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[1.0,0.0,0.0,1.0,...|[15.7765242749810...|[0.78882621374905...|       0.0|\n",
      "|      no|  crew|adult|  male|           0.0|         0.0|      0.0|      0.0|   (3,[0],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[1.0,0.0,0.0,1.0,...|[15.7765242749810...|[0.78882621374905...|       0.0|\n",
      "|      no|  crew|adult|  male|           0.0|         0.0|      0.0|      0.0|   (3,[0],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[1.0,0.0,0.0,1.0,...|[15.7765242749810...|[0.78882621374905...|       0.0|\n",
      "|      no|  crew|adult|  male|           0.0|         0.0|      0.0|      0.0|   (3,[0],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[1.0,0.0,0.0,1.0,...|[15.7765242749810...|[0.78882621374905...|       0.0|\n",
      "|      no|  crew|adult|  male|           0.0|         0.0|      0.0|      0.0|   (3,[0],[1.0])|(1,[0],[1.0])|(1,[0],[1.0])|[1.0,0.0,0.0,1.0,...|[15.7765242749810...|[0.78882621374905...|       0.0|\n",
      "+--------+------+-----+------+--------------+------------+---------+---------+----------------+-------------+-------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "(training_data, test_data) = df.randomSplit([0.7, 0.3])\n",
    "\n",
    "random_forest = RandomForestClassifier(labelCol=\"survived_index\", featuresCol=\"features\")\n",
    "\n",
    "modelo_treinado = random_forest.fit(training_data)\n",
    "\n",
    "df_previsao = modelo_treinado.transform(test_data)\n",
    "\n",
    "df_previsao.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80e75b1",
   "metadata": {},
   "source": [
    "# Avaliação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8bacf65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score do modelo: 0.7836\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"survived_index\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"f1\"\n",
    ")\n",
    "\n",
    "f1_score = evaluator.evaluate(df_previsao)\n",
    "print(f\"F1-Score do modelo: {f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c38de0f",
   "metadata": {},
   "source": [
    "# Treinamento modelo Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c542304e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score do modelo Logistic Regression: 0.7780\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Instanciando o modelo de regressão logística\n",
    "logistic_regression = LogisticRegression(labelCol=\"survived_index\", featuresCol=\"features\")\n",
    "\n",
    "# Treinando o modelo\n",
    "modelo_logistic = logistic_regression.fit(training_data)\n",
    "\n",
    "# Fazendo previsões\n",
    "df_previsao_logistic = modelo_logistic.transform(test_data)\n",
    "\n",
    "# Avaliando o modelo\n",
    "f1_score_logistic = evaluator.evaluate(df_previsao_logistic)\n",
    "print(f\"F1-Score do modelo Logistic Regression: {f1_score_logistic:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
